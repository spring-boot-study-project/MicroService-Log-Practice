input {
  kafka {
    bootstrap_servers => "kafka:19092"
    topics => ["microservice_3-logs"]
    group_id => "logstash-microservice_3"
    consumer_threads => 1
    codec => "json"
    auto_offset_reset => "earliest"
  }
}

filter {
  # LogstashEncoder로 전송된 JSON 로그 파싱
  if [message] {
    # 메시지 필드가 있는 경우 추가 파싱
    mutate {
      add_field => { "service_name" => "microservice-3" }
    }
  }
  
  # 타임스탬프 파싱
  if [@timestamp] {
    date {
      match => [ "@timestamp", "ISO8601" ]
      target => "@timestamp"
    }
  }
  
  # 로그 레벨별 인덱스 분류를 위한 필드 추가
  if [level] {
    mutate {
      add_field => { "log_level" => "%{level}" }
    }
  }
}

output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "microservice-3-logs-%{+YYYY.MM.dd}"
    user => "logstash_internal"
    password => "${LOGSTASH_INTERNAL_PASSWORD}"
  }
  
  # 디버깅용 stdout (운영환경에서는 제거 권장)
  stdout {
    codec => rubydebug
  }
}
